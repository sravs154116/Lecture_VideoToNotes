{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127c9b0b-31a6-49d8-b991-33344c89c8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faster-whisper in c:\\users\\rakes\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\rakes\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rakes\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from faster-whisper) (4.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from faster-whisper) (0.34.4)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from faster-whisper) (0.22.0)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from faster-whisper) (1.23.1)\n",
      "Requirement already satisfied: av>=11 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from faster-whisper) (15.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from ctranslate2<5,>=4.0->faster-whisper) (72.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.1.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13->faster-whisper) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13->faster-whisper) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (3.5.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faster-whisper pandas tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e44c246-26fc-4394-87a2-2dda0da060e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from faster_whisper import WhisperModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496ef1c8-62df-48b6-b46b-6863ec3a797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\Downloads\\commonvoice\\test\\test.tsv\n",
      "C:\\Users\\rakes\\Downloads\\commonvoice\\train\\train.tsv\n",
      "C:\\Users\\rakes\\Downloads\\commonvoice\\validation\\validation.tsv\n"
     ]
    }
   ],
   "source": [
    "# Path to your main Common Voice folder\n",
    "base_path = r\"C:\\Users\\rakes\\Downloads\\commonvoice\"\n",
    "\n",
    "# List all files inside it to confirm structure\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for f in files:\n",
    "        if f.endswith(\".tsv\"):\n",
    "            print(os.path.join(root, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64108c6e-15aa-4b20-a871-8d7b43faabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (2000, 8)\n",
      "Test set shape: (400, 8)\n",
      "Validation set shape: (400, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...</td>\n",
       "      <td>common_voice_en_10110</td>\n",
       "      <td>I really liked the film we saw last week.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...</td>\n",
       "      <td>common_voice_en_10153</td>\n",
       "      <td>Please put maimi yajima's song onto Operación ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e7bca7f3243636599bd8e7bbe03b4f09ae8898bb0e16e...</td>\n",
       "      <td>common_voice_en_101622</td>\n",
       "      <td>Three men are painting a metal wall white.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...</td>\n",
       "      <td>common_voice_en_10187</td>\n",
       "      <td>Though this be madness, yet there is method in it</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...</td>\n",
       "      <td>common_voice_en_10199</td>\n",
       "      <td>As she watched, the cat washed his ears and th...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id                    path  \\\n",
       "0  ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...   common_voice_en_10110   \n",
       "1  ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...   common_voice_en_10153   \n",
       "2  0e7bca7f3243636599bd8e7bbe03b4f09ae8898bb0e16e...  common_voice_en_101622   \n",
       "3  ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...   common_voice_en_10187   \n",
       "4  ac5fea9cacdfa4a2d6291c780b0a0ee1c0f2c5d2389cc0...   common_voice_en_10199   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0          I really liked the film we saw last week.         4           0   \n",
       "1  Please put maimi yajima's song onto Operación ...         3           0   \n",
       "2         Three men are painting a metal wall white.         3           0   \n",
       "3  Though this be madness, yet there is method in it         4           0   \n",
       "4  As she watched, the cat washed his ears and th...         4           0   \n",
       "\n",
       "        age gender  accent  \n",
       "0   sixties   male      us  \n",
       "1   sixties   male      us  \n",
       "2  twenties   male  indian  \n",
       "3   sixties   male      us  \n",
       "4   sixties   male      us  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ Use your confirmed paths\n",
    "train_tsv = r\"C:\\Users\\rakes\\Downloads\\commonvoice\\train\\train.tsv\"\n",
    "test_tsv = r\"C:\\Users\\rakes\\Downloads\\commonvoice\\test\\test.tsv\"\n",
    "val_tsv = r\"C:\\Users\\rakes\\Downloads\\commonvoice\\validation\\validation.tsv\"\n",
    "\n",
    "# ✅ Load the data\n",
    "train_df = pd.read_csv(train_tsv, sep=\"\\t\")\n",
    "test_df = pd.read_csv(test_tsv, sep=\"\\t\")\n",
    "val_df = pd.read_csv(val_tsv, sep=\"\\t\")\n",
    "\n",
    "# ✅ Show sample rows to verify successful loading\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5f2287-fc22-48a1-8203-ea48d9c44a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3409ed80ac9c447ba01c726e55cc1931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f43df736379439d963903ac89437b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete! Example keys: dict_keys(['input_values', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import Wav2Vec2Processor\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ✅ Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# ✅ Load processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# ✅ Path folders for each split\n",
    "train_clips_dir = r\"C:\\Users\\rakes\\Downloads\\commonvoice\\train\\clips\"\n",
    "test_clips_dir = r\"C:\\Users\\rakes\\Downloads\\commonvoice\\test\\clips\"\n",
    "val_clips_dir = r\"C:\\Users\\rakes\\Downloads\\commonvoice\\validation\\clips\"\n",
    "\n",
    "def preprocess_audio(batch, split=\"train\"):\n",
    "    # Determine correct folder\n",
    "    if split == \"train\":\n",
    "        base_path = train_clips_dir\n",
    "    elif split == \"test\":\n",
    "        base_path = test_clips_dir\n",
    "    else:\n",
    "        base_path = val_clips_dir\n",
    "\n",
    "    # Build full file path with .wav extension\n",
    "    file_name = batch[\"path\"] + \".wav\"\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {file_path}\")\n",
    "        batch[\"input_values\"] = None\n",
    "        batch[\"labels\"] = None\n",
    "        return batch\n",
    "\n",
    "    # Load audio\n",
    "    speech_array, sampling_rate = librosa.load(file_path, sr=16000)\n",
    "\n",
    "    # Extract features\n",
    "    batch[\"input_values\"] = processor(\n",
    "        speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\"\n",
    "    ).input_values[0]\n",
    "\n",
    "    batch[\"labels\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "\n",
    "# ✅ Test on a small batch\n",
    "small_train_dataset = train_dataset.select(range(10)).map(\n",
    "    lambda batch: preprocess_audio(batch, split=\"train\"),\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "print(\"✅ Preprocessing complete! Example keys:\", small_train_dataset[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "255df5d4-b0fc-49b5-b317-a23ea69510ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio features length: 93904\n",
      "Transcript: I really liked the film we saw last week.\n",
      "Audio features length: 96592\n",
      "Transcript: Please put maimi yajima's song onto Operación Bikini.\n",
      "Audio features length: 83920\n",
      "Transcript: Three men are painting a metal wall white.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    input_values = small_train_dataset[i][\"input_values\"]\n",
    "    print(\"Audio features length:\", len(input_values))  # list length instead of shape\n",
    "    print(\"Transcript:\", small_train_dataset[i][\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fbfc952-f12b-4dbd-8a76-e44a61f7103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\rakes\\appdata\\local\\temp\\pip-req-build-yj5ufhel\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (10.3.0)\n",
      "Requirement already satisfied: numba in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (0.61.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (2.1.3)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (0.12.0)\n",
      "Requirement already satisfied: torch in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20250625) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper==20250625) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\rakes\\AppData\\Local\\Temp\\pip-req-build-yj5ufhel'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\rakes\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Make sure Whisper is installed\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install ffmpeg-python\n",
    "\n",
    "# Imports\n",
    "import whisper\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e193c8d-714a-4a93-b2a4-17bc51c4e820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing clips: 100%|████████████████████████████████████████████████████████| 2000/2000 [5:35:54<00:00, 10.08s/it]\n",
      "C:\\Users\\rakes\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing clips: 100%|██████████████| 400/400 [1:00:06<00:00,  9.02s/it]\n",
      "C:\\Users\\rakes\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing clips: 100%|████████████████| 400/400 [56:06<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All transcriptions saved to: C:\\Users\\rakes\\Downloads\\commonvoice_transcriptions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>detected_language</th>\n",
       "      <th>transcript</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_en_10110.wav</td>\n",
       "      <td>en</td>\n",
       "      <td>I really like the film we saw last week.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_en_10153.wav</td>\n",
       "      <td>en</td>\n",
       "      <td>Please put Mamie Yahima's song onto Operation...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_en_101622.wav</td>\n",
       "      <td>en</td>\n",
       "      <td>3. Painting a metal ball white</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_en_10187.wav</td>\n",
       "      <td>en</td>\n",
       "      <td>Though this be madness, yet there is method i...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_en_10199.wav</td>\n",
       "      <td>en</td>\n",
       "      <td>As she watched, the cat washed his ears and t...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_name detected_language  \\\n",
       "0   common_voice_en_10110.wav                en   \n",
       "1   common_voice_en_10153.wav                en   \n",
       "2  common_voice_en_101622.wav                en   \n",
       "3   common_voice_en_10187.wav                en   \n",
       "4   common_voice_en_10199.wav                en   \n",
       "\n",
       "                                          transcript  split  \n",
       "0           I really like the film we saw last week.  train  \n",
       "1   Please put Mamie Yahima's song onto Operation...  train  \n",
       "2                     3. Painting a metal ball white  train  \n",
       "3   Though this be madness, yet there is method i...  train  \n",
       "4   As she watched, the cat washed his ears and t...  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------------------\n",
    "# Load Whisper model\n",
    "# --------------------------\n",
    "model = whisper.load_model(\"small\")  # choose \"base\", \"medium\", \"large\" for higher accuracy\n",
    "\n",
    "# --------------------------\n",
    "# Paths to Common Voice clips\n",
    "# --------------------------\n",
    "folders = {\n",
    "    \"train\": r\"C:\\Users\\rakes\\Downloads\\commonvoice\\train\\clips\",\n",
    "    \"test\": r\"C:\\Users\\rakes\\Downloads\\commonvoice\\test\\clips\",\n",
    "    \"validation\": r\"C:\\Users\\rakes\\Downloads\\commonvoice\\validation\\clips\"\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# Function to transcribe a folder\n",
    "# --------------------------\n",
    "def transcribe_folder(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".wav\")]\n",
    "    data = []\n",
    "\n",
    "    for f in tqdm(files, desc=f\"Transcribing {os.path.basename(folder_path)}\"):\n",
    "        audio_path = os.path.join(folder_path, f)\n",
    "        result = model.transcribe(audio_path)\n",
    "        data.append({\n",
    "            \"file_name\": f,\n",
    "            \"detected_language\": result[\"language\"],\n",
    "            \"transcript\": result[\"text\"]\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# --------------------------\n",
    "# Transcribe all folders\n",
    "# --------------------------\n",
    "dfs = []\n",
    "for split, path in folders.items():\n",
    "    df = transcribe_folder(path)\n",
    "    df[\"split\"] = split\n",
    "    dfs.append(df)\n",
    "\n",
    "all_transcriptions = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# --------------------------\n",
    "# Save results to CSV\n",
    "# --------------------------\n",
    "output_csv = r\"C:\\Users\\rakes\\Downloads\\commonvoice_transcriptions.csv\"\n",
    "all_transcriptions.to_csv(output_csv, index=False)\n",
    "print(f\"✅ All transcriptions saved to: {output_csv}\")\n",
    "\n",
    "# --------------------------\n",
    "# Display first 5 rows\n",
    "# --------------------------\n",
    "all_transcriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29978199-1415-4ba2-a4bc-0628784c5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import translation libraries\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Function to load translation models dynamically\n",
    "def load_translation_model(src_lang=\"en\", tgt_lang=\"fr\"):\n",
    "    \"\"\"\n",
    "    Load MarianMT model for English → target language translation.\n",
    "    Example: tgt_lang=\"hi\" for Hindi, \"te\" for Telugu, \"es\" for Spanish.\n",
    "    \"\"\"\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c91b60-37fc-4a8a-b09e-ad83ab471355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Function to translate text\n",
    "def translate_text(text, tgt_lang=\"hi\"):\n",
    "    \"\"\"\n",
    "    Translate English text into the target language.\n",
    "    \"\"\"\n",
    "    tokenizer, model = load_translation_model(\"en\", tgt_lang)\n",
    "    batch = tokenizer([text], return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**batch)\n",
    "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d607280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Make sure ffmpeg is properly set\n",
    "ffmpeg_path = r\"C:\\ffmpeg\\bin\\ffmpeg.exe\"  # update if needed\n",
    "AudioSegment.converter = ffmpeg_path\n",
    "\n",
    "# Load Whisper model once\n",
    "model = whisper.load_model(\"small\")  # or \"medium\", \"large\" for better accuracy\n",
    "\n",
    "def transcribe_video(video_path: str, translate_to_english: bool = False):\n",
    "    \"\"\"\n",
    "    Extracts audio from a video and transcribes it using Whisper.\n",
    "    If translate_to_english=True, it translates non-English speech to English.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create temp wav file\n",
    "        video_path = Path(video_path)\n",
    "        wav_path = Path(tempfile.gettempdir()) / f\"{video_path.stem}.wav\"\n",
    "\n",
    "        # Extract audio\n",
    "        audio = AudioSegment.from_file(video_path)\n",
    "        audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "        # Transcribe\n",
    "        task_type = \"translate\" if translate_to_english else \"transcribe\"\n",
    "        result = model.transcribe(str(wav_path), task=task_type)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in transcription: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078d6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup Translation Functionality\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Function to load MarianMT model dynamically\n",
    "def load_translation_model(src_lang=\"en\", tgt_lang=\"hi\"):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text, tgt_lang=\"hi\"):\n",
    "    tokenizer, model = load_translation_model(\"en\", tgt_lang)\n",
    "    batch = tokenizer([text], return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**batch)\n",
    "    return tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87134ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import whisper\n",
    "import os\n",
    "\n",
    "# Path to ffmpeg\n",
    "ffmpeg_path = r\"C:\\ffmpeg\\bin\\ffmpeg.exe\"\n",
    "AudioSegment.converter = ffmpeg_path\n",
    "\n",
    "# Load model (choose: tiny, base, small, medium, large)\n",
    "model = whisper.load_model(\"small\")\n",
    "\n",
    "def transcribe_video(video_path: str, translate_to_english: bool = False):\n",
    "    \"\"\"\n",
    "    Extracts audio from video and transcribes it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        video_path = Path(video_path)\n",
    "        wav_path = Path(tempfile.gettempdir()) / f\"{video_path.stem}.wav\"\n",
    "\n",
    "        # Extract audio\n",
    "        audio = AudioSegment.from_file(video_path)\n",
    "        audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "        # Transcribe\n",
    "        task_type = \"translate\" if translate_to_english else \"transcribe\"\n",
    "        result = model.transcribe(str(wav_path), task=task_type)\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e158e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587af6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d46c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
